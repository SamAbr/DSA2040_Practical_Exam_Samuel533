{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdaa266-4b61-4054-97e2-e0904440a37e",
   "metadata": {},
   "source": [
    "## Full ETL Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e70c2737-ffdd-4040-bb03-c220b9b2e9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 17:30:37,011 - INFO - ETL started\n",
      "2025-08-12 17:30:38,009 - INFO - Extraction: 541909 rows loaded from online_retail.csv\n",
      "2025-08-12 17:30:38,286 - INFO - Transformation: After removing missing values -> 406829 rows\n",
      "2025-08-12 17:30:38,339 - INFO - Transformation: After removing outliers -> 397884 rows\n",
      "2025-08-12 17:30:38,474 - INFO - Transformation: Latest invoice date is 2011-12-09 12:50:00, cutoff date is 2010-12-09 12:50:00\n",
      "2025-08-12 17:30:38,475 - INFO - Transformation: After last-year filter -> 384529 rows\n",
      "2025-08-12 17:30:38,580 - INFO - Transformation: Customer summary has 4277 rows\n",
      "2025-08-12 17:30:38,622 - INFO - Transformation: Time dimension has 16630 rows\n",
      "2025-08-12 17:30:41,845 - INFO - Loading: Inserted 384529 rows into SalesFact\n",
      "2025-08-12 17:30:41,846 - INFO - Loading: Inserted 4277 rows into CustomerDim\n",
      "2025-08-12 17:30:41,847 - INFO - Loading: Inserted 16630 rows into TimeDim\n",
      "2025-08-12 17:30:41,848 - INFO - ETL completed successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Task 2: ETL Process for Online Retail Dataset\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import logging\n",
    "from datetime import timedelta\n",
    "\n",
    "# ---------------------------\n",
    "# Logger setup\n",
    "# ---------------------------\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------------------\n",
    "# ETL function\n",
    "# ---------------------------\n",
    "def etl_process(csv_path, db_path=\"retail_dw.db\"):\n",
    "    try:\n",
    "        logger.info(\"ETL started\")\n",
    "\n",
    "        # ---------------------------\n",
    "        # Extract\n",
    "        # ---------------------------\n",
    "        df = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
    "        logger.info(f\"Extraction: {len(df)} rows loaded from {csv_path}\")\n",
    "\n",
    "        # Convert InvoiceDate to datetime immediately\n",
    "        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "        # ---------------------------\n",
    "        # Transform\n",
    "        # ---------------------------\n",
    "        # Remove missing values\n",
    "        df = df.dropna(subset=['CustomerID', 'InvoiceDate'])\n",
    "        logger.info(f\"Transformation: After removing missing values -> {len(df)} rows\")\n",
    "\n",
    "        # Remove outliers\n",
    "        df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "        logger.info(f\"Transformation: After removing outliers -> {len(df)} rows\")\n",
    "\n",
    "        # Calculate TotalSales\n",
    "        df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "        # Dynamic cutoff date (last year in dataset)\n",
    "        latest_date = df['InvoiceDate'].max()\n",
    "        cutoff_date = latest_date - timedelta(days=365)\n",
    "        df_last_year = df[df['InvoiceDate'] >= cutoff_date].copy()\n",
    "\n",
    "        logger.info(f\"Transformation: Latest invoice date is {latest_date}, cutoff date is {cutoff_date}\")\n",
    "        logger.info(f\"Transformation: After last-year filter -> {len(df_last_year)} rows\")\n",
    "\n",
    "        # Customer summary\n",
    "        customer_summary = (\n",
    "            df_last_year.groupby(['CustomerID', 'Country'])\n",
    "            .agg(TotalPurchases=('TotalSales', 'sum'),\n",
    "                 TotalQuantity=('Quantity', 'sum'))\n",
    "            .reset_index()\n",
    "        )\n",
    "        logger.info(f\"Transformation: Customer summary has {len(customer_summary)} rows\")\n",
    "\n",
    "        # Time dimension\n",
    "        time_dim = (\n",
    "            df_last_year[['InvoiceDate']]\n",
    "            .drop_duplicates()\n",
    "            .assign(Date=lambda x: x['InvoiceDate'].dt.date,\n",
    "                    Year=lambda x: x['InvoiceDate'].dt.year,\n",
    "                    Quarter=lambda x: x['InvoiceDate'].dt.quarter,\n",
    "                    Month=lambda x: x['InvoiceDate'].dt.month,\n",
    "                    Day=lambda x: x['InvoiceDate'].dt.day)\n",
    "        )\n",
    "        logger.info(f\"Transformation: Time dimension has {len(time_dim)} rows\")\n",
    "\n",
    "        # ---------------------------\n",
    "        # Load\n",
    "        # ---------------------------\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df_last_year.to_sql('SalesFact', conn, if_exists='replace', index=False)\n",
    "        customer_summary.to_sql('CustomerDim', conn, if_exists='replace', index=False)\n",
    "        time_dim.to_sql('TimeDim', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "\n",
    "        logger.info(f\"Loading: Inserted {len(df_last_year)} rows into SalesFact\")\n",
    "        logger.info(f\"Loading: Inserted {len(customer_summary)} rows into CustomerDim\")\n",
    "        logger.info(f\"Loading: Inserted {len(time_dim)} rows into TimeDim\")\n",
    "\n",
    "        logger.info(\"ETL completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ETL failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Run ETL\n",
    "# ---------------------------\n",
    "etl_process(\"online_retail.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914f87b-89a6-4ef4-aa40-0c859c0fc210",
   "metadata": {},
   "source": [
    "### Clarification on \"Last Year\" Filter Requirement\n",
    "\n",
    "The exam instructions specify filtering sales to the last year, assuming the current date is **August 12, 2025**.  \n",
    "If applied directly to the **Online Retail** dataset, which contains only transactions from **December 2010 to December 2011**, this filter would result in **zero rows** being selected.\n",
    "\n",
    "To fulfill the spirit of the requirement while working within the dataset’s constraints, we adapted the logic to:\n",
    "- Use the **latest available transaction date in the dataset** as the reference “current” date.\n",
    "- Subtract 365 days from this to define the cutoff for “last year.”\n",
    "\n",
    "This approach keeps the requirement’s intent (most recent year of data) but ensures meaningful output for fact and dimension tables during the exam demonstration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
